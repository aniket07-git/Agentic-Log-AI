{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f23c6e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from typing import List, Dict, Any, Optional\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain_core.tools import Tool\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Define response schema\n",
    "class ErrorResolution(BaseModel):\n",
    "    error_explanation: str = Field(description=\"Explanation of what the error means\")\n",
    "    fixes: List[str] = Field(description=\"List of potential fixes for the error\")\n",
    "    code_suggestion: str = Field(description=\"Code suggestion to fix the error\")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "            model=\"gpt-4o\",\n",
    "            temperature=0.7\n",
    "        )\n",
    "\n",
    "# File operation tools\n",
    "class FileOperations:\n",
    "    @staticmethod\n",
    "    def read_file(file_path: str) -> str:\n",
    "        \"\"\"Read the content of a file\"\"\"\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                return f.read()\n",
    "        except Exception as e:\n",
    "            return f\"Error reading file: {str(e)}\"\n",
    "\n",
    "    @staticmethod\n",
    "    def write_file(file_path: str, content: str) -> str:\n",
    "        \"\"\"Write content to a file\"\"\"\n",
    "        try:\n",
    "            with open(file_path, 'w', encoding='utf-8') as f:\n",
    "                f.write(content)\n",
    "            return f\"Content successfully written to {file_path}\"\n",
    "        except Exception as e:\n",
    "            return f\"Error writing to file: {str(e)}\"\n",
    "        \n",
    "    def list_file(self, path:str = \".\") -> str:\n",
    "        \"\"\"List files in the current directory\"\"\"\n",
    "        try:\n",
    "            files = os.listdir(path)\n",
    "            return f\"Files in the current directory: {', '.join(files)}\"\n",
    "        except Exception as e:\n",
    "            return f\"Error listing files: {str(e)}\"\n",
    "        \n",
    "# Add recursive file search capability with log file filtering\n",
    "def find_log_files(directory='.', extensions=['.log', '.txt'], max_depth=4):\n",
    "    \"\"\"\n",
    "    Recursively search for log files with specified extensions\n",
    "    \n",
    "    Args:\n",
    "        directory: Starting directory for search\n",
    "        extensions: File extensions to consider as log files\n",
    "        max_depth: Maximum recursion depth\n",
    "        \n",
    "    Returns:\n",
    "        List of log file paths found\n",
    "    \"\"\"\n",
    "    log_files = []\n",
    "    \n",
    "    def _search_dir(current_dir, current_depth):\n",
    "        if current_depth > max_depth:\n",
    "            return\n",
    "            \n",
    "        try:\n",
    "            for item in os.listdir(current_dir):\n",
    "                item_path = os.path.join(current_dir, item)\n",
    "                \n",
    "                # Check if it's a file with log extension\n",
    "                if os.path.isfile(item_path):\n",
    "                    _, ext = os.path.splitext(item_path)\n",
    "                    if ext.lower() in extensions:\n",
    "                        log_files.append(item_path)\n",
    "                \n",
    "                # Recurse into directories\n",
    "                elif os.path.isdir(item_path):\n",
    "                    _search_dir(item_path, current_depth + 1)\n",
    "        except Exception as e:\n",
    "            print(f\"Error accessing {current_dir}: {e}\")\n",
    "    \n",
    "    _search_dir(directory, 1)\n",
    "    return log_files\n",
    "\n",
    "\n",
    "# Create tools\n",
    "def create_tools():\n",
    "    file_ops = FileOperations()\n",
    "    \n",
    "    tools = [\n",
    "        Tool(\n",
    "            name=\"read_file\",\n",
    "            func=file_ops.read_file,\n",
    "            description=\"Read content from a file. Input should be the file path.\"\n",
    "        ),\n",
    "        Tool(\n",
    "            name=\"write_file\",\n",
    "            func=file_ops.write_file,\n",
    "            description=\"Write content to a file. Input should be a JSON string with 'file_path' and 'content' keys.\"\n",
    "        ),\n",
    "        Tool(\n",
    "            name=\"list_file\",\n",
    "            func=file_ops.list_file,\n",
    "            description=\"List files in the current directory.\"\n",
    "        ),\n",
    "        Tool(\n",
    "            name=\"find_log_files\",\n",
    "            func=find_log_files,\n",
    "            description=\"Find all log files (with .log or .txt extensions) in the current directory and subdirectories.\"\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    return tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "05235f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"You are an expert error resolver agent specializing in Python errors. Your task is to:\n",
    "        \n",
    "        1. First use find_log_files tool to locate all log files\n",
    "        2. Read each log file's content using read_file tool\n",
    "        3. Analyze the errors in each log file\n",
    "        4. Generate solutions for each error\n",
    "        \n",
    "        For each error:\n",
    "        1. Understand the error message and its context in traceback\n",
    "        2. Provide detailed explanation of the error\n",
    "        3. List specific fixes to resolve the error\n",
    "        4. Suggest code modifications\n",
    "        \n",
    "        IMPORTANT: Your final answer for EACH error MUST be a valid JSON object with these fields:\n",
    "        {{\n",
    "            \"error_explanation\": \"detailed explanation of what the error means and why it occurred\",\n",
    "            \"fixes\": [\"fix1\", \"fix2\", \"etc\"],\n",
    "            \"code_suggestion\": \"code snippet to fix the error\"\n",
    "        }}\n",
    "         \n",
    "         STRICTLY follow the JSON format. Do not add any other text or explanation outside of the JSON object.\n",
    "        \n",
    "        Group all errors by log file in your final response.\n",
    "        \"\"\"),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2cd3d476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting from HealthApp.log: global flags not at the start of the expression at position 1\n"
     ]
    }
   ],
   "source": [
    "from ToolKit import extract_errors_for_llm_analysis\n",
    "\n",
    "# Option 1: Extract errors from a single log file\n",
    "errors = extract_errors_for_llm_analysis(\"HealthApp.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "61acf531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No errors found in the provided logs.'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bae1db31",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = create_tools()\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "agent = create_openai_tools_agent(\n",
    "    llm=llm,\n",
    "    tools=create_tools(),\n",
    "    prompt=prompt\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    "    memory=memory,\n",
    "    return_intermediate_steps=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d0257bdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5bcb49b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `find_log_files` with `.`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m['.\\\\logs.log']\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `read_file` with `.\\logs.log`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m2025-04-25 22:54:02,462 - ERROR - Exception occurred\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\shubh\\Desktop\\Work\\Calfus_hack\\log_simulator.py\", line 20, in <module>\n",
      "    result = 1 / 0\n",
      "             ~~^~~\n",
      "ZeroDivisionError: division by zero\n",
      "2025-04-25 22:54:02,462 - ERROR - Exception occurred\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\shubh\\Desktop\\Work\\Calfus_hack\\log_simulator.py\", line 26, in <module>\n",
      "    with open('non_existent_file.txt', 'r') as f:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'non_existent_file.txt'\n",
      "2025-04-25 22:54:02,467 - ERROR - Exception occurred\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\shubh\\Desktop\\Work\\Calfus_hack\\log_simulator.py\", line 34, in <module>\n",
      "    value = d['b']\n",
      "            ~^^^^^\n",
      "KeyError: 'b'\n",
      "2025-04-25 22:54:02,467 - ERROR - Exception occurred\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\shubh\\Desktop\\Work\\Calfus_hack\\log_simulator.py\", line 41, in <module>\n",
      "    item = lst[5]\n",
      "           ~~~^^^\n",
      "IndexError: list index out of range\n",
      "2025-04-25 22:54:02,467 - ERROR - Exception occurred\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\shubh\\Desktop\\Work\\Calfus_hack\\log_simulator.py\", line 48, in <module>\n",
      "    x.append(5)\n",
      "    ^^^^^^^^\n",
      "AttributeError: 'int' object has no attribute 'append'\n",
      "2025-04-25 22:54:02,467 - ERROR - Exception occurred\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\shubh\\Desktop\\Work\\Calfus_hack\\log_simulator.py\", line 54, in <module>\n",
      "    import non_existent_module\n",
      "ModuleNotFoundError: No module named 'non_existent_module'\n",
      "2025-04-25 22:54:02,467 - ERROR - Exception occurred\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\shubh\\Desktop\\Work\\Calfus_hack\\log_simulator.py\", line 60, in <module>\n",
      "    result = 'string' + 5\n",
      "             ~~~~~~~~~^~~\n",
      "TypeError: can only concatenate str (not \"int\") to str\n",
      "2025-04-25 22:54:02,467 - ERROR - Exception occurred\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\shubh\\Desktop\\Work\\Calfus_hack\\log_simulator.py\", line 66, in <module>\n",
      "    number = int('not_a_number')\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'not_a_number'\n",
      "2025-04-25 22:54:02,467 - ERROR - Exception occurred\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\shubh\\Desktop\\Work\\Calfus_hack\\log_simulator.py\", line 72, in <module>\n",
      "    print(undefined_variable)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "NameError: name 'undefined_variable' is not defined\n",
      "2025-04-25 22:54:02,472 - ERROR - Exception occurred\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\shubh\\Desktop\\Work\\Calfus_hack\\log_simulator.py\", line 81, in <module>\n",
      "    raise CustomError(\"This is a custom error.\")\n",
      "CustomError: This is a custom error.\n",
      "\u001b[0m\u001b[32;1m\u001b[1;3mHere are the error analyses and solutions for the errors found in the log file `logs.log`:\n",
      "\n",
      "### Error 1: ZeroDivisionError\n",
      "```json\n",
      "{\n",
      "    \"error_explanation\": \"A ZeroDivisionError occurs when you attempt to divide a number by zero, which is mathematically undefined.\",\n",
      "    \"fixes\": [\"Ensure the denominator is not zero before performing division.\"],\n",
      "    \"code_suggestion\": \"if denominator != 0:\\n    result = numerator / denominator\\nelse:\\n    print('Denominator is zero, cannot divide.')\"\n",
      "}\n",
      "```\n",
      "\n",
      "### Error 2: FileNotFoundError\n",
      "```json\n",
      "{\n",
      "    \"error_explanation\": \"A FileNotFoundError occurs when an attempt is made to open a file that does not exist at the specified path.\",\n",
      "    \"fixes\": [\"Check if the file exists before trying to open it.\", \"Ensure the file path is correct.\", \"Use exception handling to handle the error gracefully.\"],\n",
      "    \"code_suggestion\": \"import os\\nif os.path.exists('non_existent_file.txt'):\\n    with open('non_existent_file.txt', 'r') as f:\\n        content = f.read()\\nelse:\\n    print('File does not exist.')\"\n",
      "}\n",
      "```\n",
      "\n",
      "### Error 3: KeyError\n",
      "```json\n",
      "{\n",
      "    \"error_explanation\": \"A KeyError occurs when trying to access a dictionary with a key that does not exist in the dictionary.\",\n",
      "    \"fixes\": [\"Check if the key exists in the dictionary before accessing it.\", \"Use the dictionary's get method to avoid KeyError.\"],\n",
      "    \"code_suggestion\": \"value = d.get('b', 'default_value')\"\n",
      "}\n",
      "```\n",
      "\n",
      "### Error 4: IndexError\n",
      "```json\n",
      "{\n",
      "    \"error_explanation\": \"An IndexError occurs when trying to access an index that is out of the range of the list.\",\n",
      "    \"fixes\": [\"Ensure the index is within the range of the list.\", \"Check the length of the list before accessing an index.\"],\n",
      "    \"code_suggestion\": \"if len(lst) > 5:\\n    item = lst[5]\\nelse:\\n    print('Index out of range.')\"\n",
      "}\n",
      "```\n",
      "\n",
      "### Error 5: AttributeError\n",
      "```json\n",
      "{\n",
      "    \"error_explanation\": \"An AttributeError occurs when trying to access an attribute or method that does not exist for the object.\",\n",
      "    \"fixes\": [\"Ensure the object is of the correct type before calling methods on it.\", \"Check the type of the object.\"],\n",
      "    \"code_suggestion\": \"if isinstance(x, list):\\n    x.append(5)\\nelse:\\n    print('x is not a list.')\"\n",
      "}\n",
      "```\n",
      "\n",
      "### Error 6: ModuleNotFoundError\n",
      "```json\n",
      "{\n",
      "    \"error_explanation\": \"A ModuleNotFoundError occurs when the Python interpreter cannot find a module that is being imported.\",\n",
      "    \"fixes\": [\"Ensure the module name is correct and that it is installed in the environment.\"],\n",
      "    \"code_suggestion\": \"# Use pip to install the module if necessary\\n# pip install module_name\\nimport existing_module\"\n",
      "}\n",
      "```\n",
      "\n",
      "### Error 7: TypeError\n",
      "```json\n",
      "{\n",
      "    \"error_explanation\": \"A TypeError occurs when an operation or function is applied to an object of inappropriate type, such as adding a string and an integer.\",\n",
      "    \"fixes\": [\"Convert the integer to a string before concatenation.\", \"Ensure both operands are of the same type.\"],\n",
      "    \"code_suggestion\": \"result = 'string' + str(5)\"\n",
      "}\n",
      "```\n",
      "\n",
      "### Error 8: ValueError\n",
      "```json\n",
      "{\n",
      "    \"error_explanation\": \"A ValueError occurs when a function receives an argument of the right type but inappropriate value, such as converting a non-numeric string to an integer.\",\n",
      "    \"fixes\": [\"Ensure the string is numeric before converting it to an integer.\", \"Use exception handling to manage conversion errors.\"],\n",
      "    \"code_suggestion\": \"try:\\n    number = int('not_a_number')\\nexcept ValueError:\\n    print('Cannot convert to integer.')\"\n",
      "}\n",
      "```\n",
      "\n",
      "### Error 9: NameError\n",
      "```json\n",
      "{\n",
      "    \"error_explanation\": \"A NameError occurs when the code attempts to use a variable that has not been defined.\",\n",
      "    \"fixes\": [\"Ensure the variable is defined before using it.\", \"Check for typos in the variable name.\"],\n",
      "    \"code_suggestion\": \"if 'undefined_variable' in locals():\\n    print(undefined_variable)\\nelse:\\n    print('Variable is not defined.')\"\n",
      "}\n",
      "```\n",
      "\n",
      "### Error 10: CustomError\n",
      "```json\n",
      "{\n",
      "    \"error_explanation\": \"CustomError is a user-defined exception that is raised intentionally by the programmer.\",\n",
      "    \"fixes\": [\"Ensure that the conditions for raising the custom error are met, or handle the exception appropriately.\"],\n",
      "    \"code_suggestion\": \"try:\\n    # some code\\n    raise CustomError('This is a custom error.')\\nexcept CustomError as e:\\n    print(e)\"\n",
      "}\n",
      "```\n",
      "\n",
      "Each error is accompanied by an explanation, possible fixes, and a code suggestion to resolve the error.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shubh\\miniconda3\\Lib\\site-packages\\langchain\\memory\\chat_memory.py:55: UserWarning: 'ConversationBufferMemory' got multiple output keys: dict_keys(['output', 'intermediate_steps']). The default 'output' key is being used. If this is not desired, please manually set 'output_key'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "res = agent_executor.invoke({\n",
    "    \"input\": \"Please find all log files in the current directory \"\".\"\" and analyze them for errors.\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "30ee0aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Here are the error analyses and solutions for the errors found in the log '\n",
      " 'file `logs.log`:\\n'\n",
      " '\\n'\n",
      " '### Error 1: ZeroDivisionError\\n'\n",
      " '```json\\n'\n",
      " '{\\n'\n",
      " '    \"error_explanation\": \"A ZeroDivisionError occurs when you attempt to '\n",
      " 'divide a number by zero, which is mathematically undefined.\",\\n'\n",
      " '    \"fixes\": [\"Ensure the denominator is not zero before performing '\n",
      " 'division.\"],\\n'\n",
      " '    \"code_suggestion\": \"if denominator != 0:\\\\n    result = numerator / '\n",
      " 'denominator\\\\nelse:\\\\n    print(\\'Denominator is zero, cannot divide.\\')\"\\n'\n",
      " '}\\n'\n",
      " '```\\n'\n",
      " '\\n'\n",
      " '### Error 2: FileNotFoundError\\n'\n",
      " '```json\\n'\n",
      " '{\\n'\n",
      " '    \"error_explanation\": \"A FileNotFoundError occurs when an attempt is made '\n",
      " 'to open a file that does not exist at the specified path.\",\\n'\n",
      " '    \"fixes\": [\"Check if the file exists before trying to open it.\", \"Ensure '\n",
      " 'the file path is correct.\", \"Use exception handling to handle the error '\n",
      " 'gracefully.\"],\\n'\n",
      " '    \"code_suggestion\": \"import os\\\\nif '\n",
      " \"os.path.exists('non_existent_file.txt'):\\\\n    with \"\n",
      " \"open('non_existent_file.txt', 'r') as f:\\\\n        content = \"\n",
      " 'f.read()\\\\nelse:\\\\n    print(\\'File does not exist.\\')\"\\n'\n",
      " '}\\n'\n",
      " '```\\n'\n",
      " '\\n'\n",
      " '### Error 3: KeyError\\n'\n",
      " '```json\\n'\n",
      " '{\\n'\n",
      " '    \"error_explanation\": \"A KeyError occurs when trying to access a '\n",
      " 'dictionary with a key that does not exist in the dictionary.\",\\n'\n",
      " '    \"fixes\": [\"Check if the key exists in the dictionary before accessing '\n",
      " 'it.\", \"Use the dictionary\\'s get method to avoid KeyError.\"],\\n'\n",
      " '    \"code_suggestion\": \"value = d.get(\\'b\\', \\'default_value\\')\"\\n'\n",
      " '}\\n'\n",
      " '```\\n'\n",
      " '\\n'\n",
      " '### Error 4: IndexError\\n'\n",
      " '```json\\n'\n",
      " '{\\n'\n",
      " '    \"error_explanation\": \"An IndexError occurs when trying to access an '\n",
      " 'index that is out of the range of the list.\",\\n'\n",
      " '    \"fixes\": [\"Ensure the index is within the range of the list.\", \"Check '\n",
      " 'the length of the list before accessing an index.\"],\\n'\n",
      " '    \"code_suggestion\": \"if len(lst) > 5:\\\\n    item = lst[5]\\\\nelse:\\\\n    '\n",
      " 'print(\\'Index out of range.\\')\"\\n'\n",
      " '}\\n'\n",
      " '```\\n'\n",
      " '\\n'\n",
      " '### Error 5: AttributeError\\n'\n",
      " '```json\\n'\n",
      " '{\\n'\n",
      " '    \"error_explanation\": \"An AttributeError occurs when trying to access an '\n",
      " 'attribute or method that does not exist for the object.\",\\n'\n",
      " '    \"fixes\": [\"Ensure the object is of the correct type before calling '\n",
      " 'methods on it.\", \"Check the type of the object.\"],\\n'\n",
      " '    \"code_suggestion\": \"if isinstance(x, list):\\\\n    '\n",
      " 'x.append(5)\\\\nelse:\\\\n    print(\\'x is not a list.\\')\"\\n'\n",
      " '}\\n'\n",
      " '```\\n'\n",
      " '\\n'\n",
      " '### Error 6: ModuleNotFoundError\\n'\n",
      " '```json\\n'\n",
      " '{\\n'\n",
      " '    \"error_explanation\": \"A ModuleNotFoundError occurs when the Python '\n",
      " 'interpreter cannot find a module that is being imported.\",\\n'\n",
      " '    \"fixes\": [\"Ensure the module name is correct and that it is installed in '\n",
      " 'the environment.\"],\\n'\n",
      " '    \"code_suggestion\": \"# Use pip to install the module if necessary\\\\n# pip '\n",
      " 'install module_name\\\\nimport existing_module\"\\n'\n",
      " '}\\n'\n",
      " '```\\n'\n",
      " '\\n'\n",
      " '### Error 7: TypeError\\n'\n",
      " '```json\\n'\n",
      " '{\\n'\n",
      " '    \"error_explanation\": \"A TypeError occurs when an operation or function '\n",
      " 'is applied to an object of inappropriate type, such as adding a string and '\n",
      " 'an integer.\",\\n'\n",
      " '    \"fixes\": [\"Convert the integer to a string before concatenation.\", '\n",
      " '\"Ensure both operands are of the same type.\"],\\n'\n",
      " '    \"code_suggestion\": \"result = \\'string\\' + str(5)\"\\n'\n",
      " '}\\n'\n",
      " '```\\n'\n",
      " '\\n'\n",
      " '### Error 8: ValueError\\n'\n",
      " '```json\\n'\n",
      " '{\\n'\n",
      " '    \"error_explanation\": \"A ValueError occurs when a function receives an '\n",
      " 'argument of the right type but inappropriate value, such as converting a '\n",
      " 'non-numeric string to an integer.\",\\n'\n",
      " '    \"fixes\": [\"Ensure the string is numeric before converting it to an '\n",
      " 'integer.\", \"Use exception handling to manage conversion errors.\"],\\n'\n",
      " '    \"code_suggestion\": \"try:\\\\n    number = int(\\'not_a_number\\')\\\\nexcept '\n",
      " 'ValueError:\\\\n    print(\\'Cannot convert to integer.\\')\"\\n'\n",
      " '}\\n'\n",
      " '```\\n'\n",
      " '\\n'\n",
      " '### Error 9: NameError\\n'\n",
      " '```json\\n'\n",
      " '{\\n'\n",
      " '    \"error_explanation\": \"A NameError occurs when the code attempts to use a '\n",
      " 'variable that has not been defined.\",\\n'\n",
      " '    \"fixes\": [\"Ensure the variable is defined before using it.\", \"Check for '\n",
      " 'typos in the variable name.\"],\\n'\n",
      " '    \"code_suggestion\": \"if \\'undefined_variable\\' in locals():\\\\n    '\n",
      " \"print(undefined_variable)\\\\nelse:\\\\n    print('Variable is not \"\n",
      " 'defined.\\')\"\\n'\n",
      " '}\\n'\n",
      " '```\\n'\n",
      " '\\n'\n",
      " '### Error 10: CustomError\\n'\n",
      " '```json\\n'\n",
      " '{\\n'\n",
      " '    \"error_explanation\": \"CustomError is a user-defined exception that is '\n",
      " 'raised intentionally by the programmer.\",\\n'\n",
      " '    \"fixes\": [\"Ensure that the conditions for raising the custom error are '\n",
      " 'met, or handle the exception appropriately.\"],\\n'\n",
      " '    \"code_suggestion\": \"try:\\\\n    # some code\\\\n    raise '\n",
      " \"CustomError('This is a custom error.')\\\\nexcept CustomError as e:\\\\n    \"\n",
      " 'print(e)\"\\n'\n",
      " '}\\n'\n",
      " '```\\n'\n",
      " '\\n'\n",
      " 'Each error is accompanied by an explanation, possible fixes, and a code '\n",
      " 'suggestion to resolve the error.')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(res[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "060439d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_code_files(root_dir: str, extensions: Optional[List[str]] = None) -> List[str]:\n",
    "    \"\"\"\n",
    "    Recursively lists all files in root_dir matching given extensions.\n",
    "    Returns a list of absolute file paths.\n",
    "    \"\"\"\n",
    "    if extensions is None:\n",
    "        extensions = ['.py', '.js', '.ts', '.java', '.cpp', '.go', '.rb', '.rs']\n",
    "    code_files = []\n",
    "    for dirpath, _, filenames in os.walk(root_dir):\n",
    "        for f in filenames:\n",
    "            if any(f.endswith(ext) for ext in extensions):\n",
    "                abs_path = os.path.abspath(os.path.join(dirpath, f))\n",
    "                code_files.append(abs_path)\n",
    "    return code_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1bea9c39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c:\\\\Users\\\\shubh\\\\Desktop\\\\Work\\\\Calfus_hack\\\\agent.py',\n",
       " 'c:\\\\Users\\\\shubh\\\\Desktop\\\\Work\\\\Calfus_hack\\\\app.py',\n",
       " 'c:\\\\Users\\\\shubh\\\\Desktop\\\\Work\\\\Calfus_hack\\\\codebase_QA.py',\n",
       " 'c:\\\\Users\\\\shubh\\\\Desktop\\\\Work\\\\Calfus_hack\\\\database.py',\n",
       " 'c:\\\\Users\\\\shubh\\\\Desktop\\\\Work\\\\Calfus_hack\\\\driver.py',\n",
       " 'c:\\\\Users\\\\shubh\\\\Desktop\\\\Work\\\\Calfus_hack\\\\log_obs.py',\n",
       " 'c:\\\\Users\\\\shubh\\\\Desktop\\\\Work\\\\Calfus_hack\\\\log_simulator.py',\n",
       " 'c:\\\\Users\\\\shubh\\\\Desktop\\\\Work\\\\Calfus_hack\\\\main.py',\n",
       " 'c:\\\\Users\\\\shubh\\\\Desktop\\\\Work\\\\Calfus_hack\\\\sample\\\\loganalyzer\\\\analyzer.py',\n",
       " 'c:\\\\Users\\\\shubh\\\\Desktop\\\\Work\\\\Calfus_hack\\\\sample\\\\loganalyzer\\\\api.py',\n",
       " 'c:\\\\Users\\\\shubh\\\\Desktop\\\\Work\\\\Calfus_hack\\\\sample\\\\loganalyzer\\\\main.py',\n",
       " 'c:\\\\Users\\\\shubh\\\\Desktop\\\\Work\\\\Calfus_hack\\\\sample\\\\loganalyzer\\\\monitor.py',\n",
       " 'c:\\\\Users\\\\shubh\\\\Desktop\\\\Work\\\\Calfus_hack\\\\sample\\\\loganalyzer\\\\output.py',\n",
       " 'c:\\\\Users\\\\shubh\\\\Desktop\\\\Work\\\\Calfus_hack\\\\sample\\\\loganalyzer\\\\__init__.py']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_code_files(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6895b53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "def load_with_line_metadata(file_path: str, chunk_size: int = 200) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Loads a file and splits into Document chunks with line number metadata.\n",
    "    Uses absolute file paths for reliable reference.\n",
    "    \"\"\"\n",
    "    docs = []\n",
    "    # Convert to absolute path to ensure consistency\n",
    "    abs_file_path = os.path.abspath(file_path)\n",
    "    \n",
    "    try:\n",
    "        with open(abs_file_path, 'r', encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "            \n",
    "        for i in range(0, len(lines), chunk_size):\n",
    "            chunk_lines = lines[i:i + chunk_size]\n",
    "            docs.append(\n",
    "                Document(\n",
    "                    page_content=''.join(chunk_lines),\n",
    "                    metadata={\n",
    "                        'source': abs_file_path,  # Store absolute path\n",
    "                        'start_line': i + 1,\n",
    "                        'end_line': i + len(chunk_lines)\n",
    "                    }\n",
    "                )\n",
    "            )\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {abs_file_path}: {str(e)}\")\n",
    "    \n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3ad2f7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_files = list_code_files('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c83e235d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'c:\\\\Users\\\\shubh\\\\Desktop\\\\Work\\\\Calfus_hack\\\\agent.py', 'start_line': 1, 'end_line': 10}, page_content='import os\\nimport json\\nimport re\\nfrom typing import List, Dict, Any, Optional\\nimport logging\\nfrom langchain_openai import ChatOpenAI\\nfrom langchain.agents import AgentExecutor, create_openai_tools_agent\\nfrom langchain_core.tools import Tool\\nfrom langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\\nfrom langchain.pydantic_v1 import BaseModel, Field\\n'),\n",
       " Document(metadata={'source': 'c:\\\\Users\\\\shubh\\\\Desktop\\\\Work\\\\Calfus_hack\\\\agent.py', 'start_line': 11, 'end_line': 20}, page_content='from langchain.memory import ConversationBufferMemory\\nfrom dotenv import load_dotenv\\n\\n# Load environment variables\\nload_dotenv()\\n\\n# Configure logging\\nlogging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\\nlogger = logging.getLogger(__name__)\\n\\n'),\n",
       " Document(metadata={'source': 'c:\\\\Users\\\\shubh\\\\Desktop\\\\Work\\\\Calfus_hack\\\\agent.py', 'start_line': 21, 'end_line': 30}, page_content='# Define response schema\\nclass ErrorResolution(BaseModel):\\n    error_explanation: str = Field(description=\"Explanation of what the error means\")\\n    fixes: List[str] = Field(description=\"List of potential fixes for the error\")\\n    code_suggestion: str = Field(description=\"Code suggestion to fix the error\")\\n\\n# File operation tools\\nclass FileOperations:\\n    @staticmethod\\n    def read_file(file_path: str) -> str:\\n'),\n",
       " Document(metadata={'source': 'c:\\\\Users\\\\shubh\\\\Desktop\\\\Work\\\\Calfus_hack\\\\agent.py', 'start_line': 31, 'end_line': 40}, page_content='        \"\"\"Read the content of a file\"\"\"\\n        try:\\n            with open(file_path, \\'r\\', encoding=\\'utf-8\\') as f:\\n                return f.read()\\n        except Exception as e:\\n            logger.error(f\"Error reading file {file_path}: {str(e)}\")\\n            return f\"Error reading file: {str(e)}\"\\n\\n    @staticmethod\\n    def write_file(file_path: str, content: str) -> str:\\n'),\n",
       " Document(metadata={'source': 'c:\\\\Users\\\\shubh\\\\Desktop\\\\Work\\\\Calfus_hack\\\\agent.py', 'start_line': 41, 'end_line': 50}, page_content='        \"\"\"Write content to a file\"\"\"\\n        try:\\n            with open(file_path, \\'w\\', encoding=\\'utf-8\\') as f:\\n                f.write(content)\\n            return f\"Content successfully written to {file_path}\"\\n        except Exception as e:\\n            logger.error(f\"Error writing to file {file_path}: {str(e)}\")\\n            return f\"Error writing to file: {str(e)}\"\\n\\n# Create tools\\n'),\n",
       " Document(metadata={'source': 'c:\\\\Users\\\\shubh\\\\Desktop\\\\Work\\\\Calfus_hack\\\\agent.py', 'start_line': 51, 'end_line': 60}, page_content='def create_tools():\\n    file_ops = FileOperations()\\n    \\n    tools = [\\n        Tool(\\n            name=\"read_file\",\\n            func=file_ops.read_file,\\n            description=\"Read content from a file. Input should be the file path.\"\\n        ),\\n        Tool(\\n'),\n",
       " Document(metadata={'source': 'c:\\\\Users\\\\shubh\\\\Desktop\\\\Work\\\\Calfus_hack\\\\agent.py', 'start_line': 61, 'end_line': 70}, page_content='            name=\"write_file\",\\n            func=file_ops.write_file,\\n            description=\"Write content to a file. Input should be a JSON string with \\'file_path\\' and \\'content\\' keys.\"\\n        )\\n    ]\\n    \\n    return tools\\n\\n# Log parsing functions\\ndef extract_errors_from_log(log_content: str) -> List[str]:\\n'),\n",
       " Document(metadata={'source': 'c:\\\\Users\\\\shubh\\\\Desktop\\\\Work\\\\Calfus_hack\\\\agent.py', 'start_line': 71, 'end_line': 80}, page_content='    \"\"\"Extract individual error entries from a log file with Python traceback format\"\"\"\\n    # Look for patterns like: timestamp - ERROR - Exception occurred followed by traceback\\n    error_pattern = r\\'\\\\d{4}-\\\\d{2}-\\\\d{2} \\\\d{2}:\\\\d{2}:\\\\d{2},\\\\d{3} - ERROR.*?(?=\\\\d{4}-\\\\d{2}-\\\\d{2} \\\\d{2}:\\\\d{2}:\\\\d{2},\\\\d{3}|\\\\Z)\\'\\n    errors = re.findall(error_pattern, log_content, re.DOTALL)\\n    \\n    # Clean up and filter errors\\n    cleaned_errors = [error.strip() for error in errors if error.strip()]\\n    return cleaned_errors\\n\\n# Agent creation\\n'),\n",
       " Document(metadata={'source': 'c:\\\\Users\\\\shubh\\\\Desktop\\\\Work\\\\Calfus_hack\\\\agent.py', 'start_line': 81, 'end_line': 90}, page_content='def create_error_resolver_agent(llm):\\n    tools = create_tools()\\n    \\n    prompt = ChatPromptTemplate.from_messages([\\n        (\"system\", \"\"\"You are an expert error resolver agent specializing in Python errors. Your task is to analyze and fix errors from logs.\\n        \\n        For each error:\\n        1. Understand the error message and its context in the traceback\\n        2. Search for solutions using DuckDuckGo if needed\\n        3. Provide a detailed explanation of what caused the error\\n'),\n",
       " Document(metadata={'source': 'c:\\\\Users\\\\shubh\\\\Desktop\\\\Work\\\\Calfus_hack\\\\agent.py', 'start_line': 91, 'end_line': 100}, page_content='        4. List specific fixes to resolve the error\\n        5. Suggest code modifications with corrected code\\n        \\n        IMPORTANT: Your final answer MUST be in valid JSON format with these fields:\\n        - error_explanation: detailed explanation of what the error means and why it occurred\\n        - fixes: list of potential solutions as string items\\n        - code_suggestion: code snippet to fix the error (ONLY CODE, no explanation)\\n        \\n        Do not include any additional formatting, markdown, or explanations outside the JSON.\\n        \"\"\"),\\n'),\n",
       " Document(metadata={'source': 'c:\\\\Users\\\\shubh\\\\Desktop\\\\Work\\\\Calfus_hack\\\\agent.py', 'start_line': 101, 'end_line': 110}, page_content='        MessagesPlaceholder(variable_name=\"chat_history\"),\\n        (\"human\", \"{input}\"),\\n        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\\n    ])\\n    \\n    memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\\n    agent = create_openai_tools_agent(llm, tools, prompt)\\n    agent_executor = AgentExecutor(\\n        agent=agent,\\n        tools=tools,\\n'),\n",
       " Document(metadata={'source': 'c:\\\\Users\\\\shubh\\\\Desktop\\\\Work\\\\Calfus_hack\\\\agent.py', 'start_line': 111, 'end_line': 120}, page_content='        memory=memory,\\n        verbose=True,\\n        handle_parsing_errors=True,\\n    )\\n    \\n    return agent_executor\\n\\nclass ErrorResolverAgent:\\n    def __init__(self, model_name=\"gpt-4o\", temperature=0):\\n        # Initialize the LLM\\n'),\n",
       " Document(metadata={'source': 'c:\\\\Users\\\\shubh\\\\Desktop\\\\Work\\\\Calfus_hack\\\\agent.py', 'start_line': 121, 'end_line': 130}, page_content='        self.llm = ChatOpenAI(\\n            model=model_name,\\n            temperature=temperature\\n        )\\n        self.agent = create_error_resolver_agent(self.llm)\\n        \\n    def resolve_log_file(self, log_file_path: str, output_file_path: Optional[str] = None) -> List[Dict]:\\n        \"\"\"Process a log file and resolve errors\"\"\"\\n        # Read log file\\n        log_content = FileOperations.read_file(log_file_path)\\n'),\n",
       " Document(metadata={'source': 'c:\\\\Users\\\\shubh\\\\Desktop\\\\Work\\\\Calfus_hack\\\\agent.py', 'start_line': 131, 'end_line': 140}, page_content='        \\n        # Extract errors\\n        errors = extract_errors_from_log(log_content)\\n        logger.info(f\"Found {len(errors)} errors in the log file\")\\n        \\n        # Process errors using the agent\\n        resolutions = self.process_errors_with_agent(errors)\\n        \\n        # Write to output file if specified\\n        if output_file_path:\\n'),\n",
       " Document(metadata={'source': 'c:\\\\Users\\\\shubh\\\\Desktop\\\\Work\\\\Calfus_hack\\\\agent.py', 'start_line': 141, 'end_line': 150}, page_content='            FileOperations.write_file(output_file_path, json.dumps(resolutions, indent=2))\\n            logger.info(f\"Results written to {output_file_path}\")\\n        \\n        return resolutions\\n\\n    def process_errors_with_agent(self, errors: List[str]) -> List[Dict]:\\n        \"\"\"Process errors using the agent and return resolutions\"\"\"\\n        resolutions = []\\n        \\n        for i, error in enumerate(errors):\\n'),\n",
       " Document(metadata={'source': 'c:\\\\Users\\\\shubh\\\\Desktop\\\\Work\\\\Calfus_hack\\\\agent.py', 'start_line': 151, 'end_line': 160}, page_content='            logger.info(f\"Processing error {i+1}/{len(errors)}\")\\n            \\n            # Send to agent\\n            query = f\"\"\"\\n            Please analyze this Python error and provide a solution:\\n            ```\\n            {error}\\n            ```\\n            Return your analysis in JSON format with error_explanation, fixes, and code_suggestion fields.\\n            \"\"\"\\n'),\n",
       " Document(metadata={'source': 'c:\\\\Users\\\\shubh\\\\Desktop\\\\Work\\\\Calfus_hack\\\\agent.py', 'start_line': 161, 'end_line': 170}, page_content='            \\n            response = self.agent.invoke({\"input\": query})\\n            \\n            # Extract response and convert to structured format using eval or json\\n            try:\\n                if isinstance(response[\"output\"], str):\\n                    # Attempt to parse the response as JSON\\n                    resolution = json.loads(response[\"output\"])\\n                    resolutions.append(resolution)\\n                else:\\n'),\n",
       " Document(metadata={'source': 'c:\\\\Users\\\\shubh\\\\Desktop\\\\Work\\\\Calfus_hack\\\\agent.py', 'start_line': 171, 'end_line': 180}, page_content='                    logger.warning(\"Response not in expected format\")\\n                    resolutions.append({\\n                        \"error_explanation\": \"Failed to parse agent response\",\\n                        \"fixes\": [\"See raw response\"],\\n                        \"code_suggestion\": \"# No code suggestion available\"\\n                    })\\n            except json.JSONDecodeError as e:\\n                logger.error(f\"JSON decoding error: {str(e)}\")\\n                resolutions.append({\\n                    \"error_explanation\": f\"Error decoding JSON: {str(e)}\",\\n'),\n",
       " Document(metadata={'source': 'c:\\\\Users\\\\shubh\\\\Desktop\\\\Work\\\\Calfus_hack\\\\agent.py', 'start_line': 181, 'end_line': 190}, page_content='                    \"fixes\": [\"See raw response\"],\\n                    \"code_suggestion\": \"# No code suggestion available\"\\n                })\\n            except Exception as e:\\n                logger.error(f\"Error processing agent response: {str(e)}\")\\n                resolutions.append({\\n                    \"error_explanation\": f\"Error processing response: {str(e)}\",\\n                    \"fixes\": [\"See raw response\"],\\n                    \"code_suggestion\": \"# No code suggestion available\"\\n                })\\n'),\n",
       " Document(metadata={'source': 'c:\\\\Users\\\\shubh\\\\Desktop\\\\Work\\\\Calfus_hack\\\\agent.py', 'start_line': 191, 'end_line': 200}, page_content='        \\n        return resolutions\\n\\ndef main():\\n    # Example usage\\n    resolver = ErrorResolverAgent()\\n    log_file_path = input(\"Enter the path to the log file: \")\\n    output_file_path = \"output.json\"\\n    \\n    resolutions = resolver.resolve_log_file(log_file_path, output_file_path)\\n'),\n",
       " Document(metadata={'source': 'c:\\\\Users\\\\shubh\\\\Desktop\\\\Work\\\\Calfus_hack\\\\agent.py', 'start_line': 201, 'end_line': 210}, page_content='    \\n    # Print summary\\n    print(\"\\\\n=== Error Resolution Summary ===\")\\n    for i, res in enumerate(resolutions):\\n        print(f\"\\\\nError #{i+1}:\")\\n        print(f\"- Explanation: {res[\\'error_explanation\\'][:100]}...\" if len(res[\\'error_explanation\\']) > 100 else f\"- Explanation: {res[\\'error_explanation\\']}\")\\n        print(f\"- Fixes: {\\', \\'.join(res[\\'fixes\\'][:3])}\" + (\"...\" if len(res[\\'fixes\\']) > 3 else \"\"))\\n        print(\"- Code suggestion available: Yes\" if res[\\'code_suggestion\\'].strip() else \"- Code suggestion available: No\")\\n\\nif __name__ == \"__main__\":\\n'),\n",
       " Document(metadata={'source': 'c:\\\\Users\\\\shubh\\\\Desktop\\\\Work\\\\Calfus_hack\\\\agent.py', 'start_line': 211, 'end_line': 211}, page_content='    main()')]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_with_line_metadata(code_files[0], chunk_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "61ce6ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(full_path, st, end):\n",
    "    \"\"\"\n",
    "    Reads raw text from code files.\n",
    "    Accepts the full file path, start line (st), and end line (end) as arguments.\n",
    "    If st=0 and end=0, the entire file is read.\n",
    "    \"\"\"\n",
    "    # Ensure the path is valid\n",
    "    if not os.path.exists(full_path):\n",
    "        return f\"Error: File not found: {full_path}\"\n",
    "\n",
    "    # Read the file\n",
    "    try:\n",
    "        with open(full_path, 'r', encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        # If st=0 and end=0, read the entire file\n",
    "        if st == 0 and end == 0:\n",
    "            return ''.join(lines)\n",
    "\n",
    "        # Clamp values\n",
    "        st = max(1, st)\n",
    "        end = min(len(lines), end) if end > 0 else len(lines)\n",
    "\n",
    "        # Return the requested lines\n",
    "        return ''.join(lines[st - 1: end])\n",
    "    except Exception as e:\n",
    "        return f\"Error reading file: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "14012550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import os\\nimport json\\nimport re\\nfrom typing import List, Dict, Any, Optional\\nimport logging\\nfrom langchain_openai import ChatOpenAI\\nfrom langchain.agents import AgentExecutor, create_openai_tools_agent\\nfrom langchain_core.tools import Tool\\nfrom langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\\nfrom langchain.pydantic_v1 import BaseModel, Field\\n'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_file(code_files[0], 1, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07718e1",
   "metadata": {},
   "source": [
    "# Fetching Logs from Loki\n",
    "\n",
    "This section adds functionality to fetch logs from a Loki instance for advanced log analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f83a127",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import urllib.parse\n",
    "\n",
    "class LokiLogFetcher:\n",
    "    def __init__(self, base_url=\"http://localhost:3100\"):\n",
    "        \"\"\"Initialize the Loki log fetcher with the Loki server URL.\n",
    "        \n",
    "        Args:\n",
    "            base_url: The URL of the Loki server, default is http://localhost:3100\n",
    "        \"\"\"\n",
    "        self.base_url = base_url\n",
    "        self.query_endpoint = f\"{base_url}/loki/api/v1/query_range\"\n",
    "    \n",
    "    def query_logs(self, query, start_time=None, end_time=None, limit=100, direction=\"BACKWARD\"):\n",
    "        \"\"\"Query logs from Loki.\n",
    "        \n",
    "        Args:\n",
    "            query: LogQL query string\n",
    "            start_time: Start time in ISO format or datetime object\n",
    "            end_time: End time in ISO format or datetime object\n",
    "            limit: Maximum number of entries to return\n",
    "            direction: Query direction (BACKWARD or FORWARD)\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame containing the logs or raw response if pandas is not available\n",
    "        \"\"\"\n",
    "        # Set default time range if not provided\n",
    "        if end_time is None:\n",
    "            end_time = datetime.now()\n",
    "        if start_time is None:\n",
    "            start_time = end_time - timedelta(hours=1)\n",
    "            \n",
    "        # Convert datetime objects to ISO format strings\n",
    "        if isinstance(start_time, datetime):\n",
    "            start_time = start_time.isoformat()\n",
    "        if isinstance(end_time, datetime):\n",
    "            end_time = end_time.isoformat()\n",
    "            \n",
    "        # Prepare query parameters\n",
    "        params = {\n",
    "            \"query\": query,\n",
    "            \"start\": start_time,\n",
    "            \"end\": end_time,\n",
    "            \"limit\": limit,\n",
    "            \"direction\": direction\n",
    "        }\n",
    "        \n",
    "        # Make the request to Loki\n",
    "        try:\n",
    "            response = requests.get(self.query_endpoint, params=params)\n",
    "            response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "            data = response.json()\n",
    "            \n",
    "            # Process the response into a DataFrame\n",
    "            if \"data\" in data and \"result\" in data[\"data\"]:\n",
    "                results = data[\"data\"][\"result\"]\n",
    "                \n",
    "                # Prepare data for DataFrame\n",
    "                log_entries = []\n",
    "                for result in results:\n",
    "                    labels = result.get(\"stream\", {})\n",
    "                    for value in result.get(\"values\", []):\n",
    "                        timestamp_ns, log_line = value\n",
    "                        timestamp = datetime.fromtimestamp(int(timestamp_ns) / 1e9)\n",
    "                        entry = {\n",
    "                            \"timestamp\": timestamp,\n",
    "                            \"log\": log_line,\n",
    "                            **labels  # Include all labels as columns\n",
    "                        }\n",
    "                        log_entries.append(entry)\n",
    "                \n",
    "                if log_entries:\n",
    "                    return pd.DataFrame(log_entries)\n",
    "                else:\n",
    "                    print(\"No log entries found.\")\n",
    "                    return pd.DataFrame()\n",
    "            else:\n",
    "                print(f\"Unexpected response format: {data}\")\n",
    "                return data\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error querying Loki: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def analyze_error_patterns(self, logs_df):\n",
    "        \"\"\"Analyze error patterns in the logs.\n",
    "        \n",
    "        Args:\n",
    "            logs_df: DataFrame containing logs\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with error analysis\n",
    "        \"\"\"\n",
    "        if logs_df is None or logs_df.empty:\n",
    "            return {\"error\": \"No logs to analyze\"}\n",
    "            \n",
    "        # Filter for error logs (customize based on your log format)\n",
    "        error_df = logs_df[logs_df[\"log\"].str.contains(\"error|exception|fail\", case=False, regex=True)].copy()\n",
    "        \n",
    "        # Count occurrences of different error types\n",
    "        error_counts = {}\n",
    "        error_patterns = [\n",
    "            (\"ZeroDivisionError\", r\"ZeroDivisionError\"),\n",
    "            (\"FileNotFoundError\", r\"FileNotFoundError\"),\n",
    "            (\"KeyError\", r\"KeyError\"),\n",
    "            (\"IndexError\", r\"IndexError\"),\n",
    "            (\"AttributeError\", r\"AttributeError\"),\n",
    "            (\"TypeError\", r\"TypeError\"),\n",
    "            (\"ValueError\", r\"ValueError\"),\n",
    "            (\"NameError\", r\"NameError\"),\n",
    "            (\"Import Error\", r\"ImportError|ModuleNotFoundError\"),\n",
    "            (\"Permission Error\", r\"PermissionError\"),\n",
    "            (\"Connection Error\", r\"ConnectionError|ConnectionRefusedError\"),\n",
    "            (\"Timeout Error\", r\"TimeoutError\"),\n",
    "            (\"Other Error\", r\"Error|Exception\")  # Catch-all for other errors\n",
    "        ]\n",
    "        \n",
    "        for error_name, pattern in error_patterns:\n",
    "            mask = error_df[\"log\"].str.contains(pattern, case=False, regex=True)\n",
    "            count = mask.sum()\n",
    "            if count > 0:\n",
    "                error_counts[error_name] = count\n",
    "                \n",
    "        # Time series analysis of errors\n",
    "        error_df[\"hour\"] = error_df[\"timestamp\"].dt.hour\n",
    "        hourly_counts = error_df.groupby(\"hour\").size().to_dict()\n",
    "        \n",
    "        return {\n",
    "            \"total_logs\": len(logs_df),\n",
    "            \"error_logs\": len(error_df),\n",
    "            \"error_types\": error_counts,\n",
    "            \"hourly_distribution\": hourly_counts\n",
    "        }\n",
    "\n",
    "# Create an instance of the Loki log fetcher\n",
    "loki_fetcher = LokiLogFetcher(base_url=\"http://localhost:3100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebffad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example query to fetch error logs from Loki\n",
    "# Replace with your actual label selectors\n",
    "query = '{job=\"application\"}'\n",
    "\n",
    "# Get logs from the last hour (modify as needed)\n",
    "end_time = datetime.now()\n",
    "start_time = end_time - timedelta(hours=1)\n",
    "\n",
    "try:\n",
    "    # Fetch logs\n",
    "    logs_df = loki_fetcher.query_logs(\n",
    "        query=query,\n",
    "        start_time=start_time,\n",
    "        end_time=end_time,\n",
    "        limit=1000\n",
    "    )\n",
    "    \n",
    "    if logs_df is not None and not logs_df.empty:\n",
    "        print(f\"Retrieved {len(logs_df)} log entries.\")\n",
    "        # Display the first few log entries\n",
    "        display(logs_df.head())\n",
    "    else:\n",
    "        print(\"No logs retrieved or connection failed.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error fetching logs: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6439e29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze error patterns in the retrieved logs\n",
    "try:\n",
    "    if 'logs_df' in locals() and logs_df is not None and not logs_df.empty:\n",
    "        error_analysis = loki_fetcher.analyze_error_patterns(logs_df)\n",
    "        \n",
    "        # Display error analysis results\n",
    "        print(f\"Total logs analyzed: {error_analysis['total_logs']}\")\n",
    "        print(f\"Error logs found: {error_analysis['error_logs']} ({error_analysis['error_logs']/error_analysis['total_logs']*100:.2f}%)\\n\")\n",
    "        \n",
    "        print(\"Error type distribution:\")\n",
    "        for error_type, count in error_analysis['error_types'].items():\n",
    "            print(f\"  - {error_type}: {count} occurrences\")\n",
    "        \n",
    "        # Create a bar chart of error types\n",
    "        if error_analysis['error_types']:\n",
    "            error_types_df = pd.DataFrame(list(error_analysis['error_types'].items()), \n",
    "                                         columns=['Error Type', 'Count'])\n",
    "            error_types_df.sort_values('Count', ascending=False, inplace=True)\n",
    "            \n",
    "            # Plot using matplotlib\n",
    "            import matplotlib.pyplot as plt\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            plt.bar(error_types_df['Error Type'], error_types_df['Count'])\n",
    "            plt.xticks(rotation=45, ha='right')\n",
    "            plt.title('Error Types in Logs')\n",
    "            plt.xlabel('Error Type')\n",
    "            plt.ylabel('Count')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Plot hourly distribution\n",
    "            if error_analysis['hourly_distribution']:\n",
    "                hours = sorted(error_analysis['hourly_distribution'].keys())\n",
    "                counts = [error_analysis['hourly_distribution'][h] for h in hours]\n",
    "                \n",
    "                plt.figure(figsize=(12, 6))\n",
    "                plt.plot(hours, counts, marker='o')\n",
    "                plt.title('Hourly Distribution of Errors')\n",
    "                plt.xlabel('Hour')\n",
    "                plt.ylabel('Error Count')\n",
    "                plt.xticks(range(0, 24, 1))\n",
    "                plt.grid(True, alpha=0.3)\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "    else:\n",
    "        print(\"No logs available for analysis.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during analysis: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46c11fc",
   "metadata": {},
   "source": [
    "## Advanced Error Analysis with LLM\n",
    "\n",
    "Using our existing agent to analyze specific error messages from Loki logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b843e74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_error_contexts(logs_df, error_pattern=\"error|exception|fail\", context_lines=5):\n",
    "    \"\"\"Extract error messages with surrounding context.\n",
    "    \n",
    "    Args:\n",
    "        logs_df: DataFrame containing logs\n",
    "        error_pattern: Regex pattern to identify error logs\n",
    "        context_lines: Number of lines of context before and after the error\n",
    "        \n",
    "    Returns:\n",
    "        List of dictionaries containing error contexts\n",
    "    \"\"\"\n",
    "    if logs_df is None or logs_df.empty:\n",
    "        return []\n",
    "        \n",
    "    # Create a copy and ensure logs are sorted by timestamp\n",
    "    df = logs_df.sort_values('timestamp').copy()\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Find error log indices\n",
    "    error_indices = df[df['log'].str.contains(error_pattern, case=False, regex=True)].index\n",
    "    \n",
    "    error_contexts = []\n",
    "    for idx in error_indices:\n",
    "        # Get context before and after the error\n",
    "        start_idx = max(0, idx - context_lines)\n",
    "        end_idx = min(len(df) - 1, idx + context_lines)\n",
    "        \n",
    "        context_logs = df.loc[start_idx:end_idx, 'log'].tolist()\n",
    "        error_log = df.loc[idx, 'log']\n",
    "        timestamp = df.loc[idx, 'timestamp']\n",
    "        \n",
    "        # Extract additional context if available\n",
    "        labels = {col: df.loc[idx, col] for col in df.columns \n",
    "                  if col not in ['timestamp', 'log', 'hour']}\n",
    "        \n",
    "        error_contexts.append({\n",
    "            'timestamp': timestamp,\n",
    "            'error_log': error_log,\n",
    "            'context_logs': context_logs,\n",
    "            'labels': labels\n",
    "        })\n",
    "    \n",
    "    return error_contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f642755a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract error contexts from the logs\n",
    "if 'logs_df' in locals() and logs_df is not None and not logs_df.empty:\n",
    "    error_contexts = extract_error_contexts(logs_df)\n",
    "    print(f\"Found {len(error_contexts)} errors with context.\")\n",
    "    \n",
    "    # Display the first error context as an example\n",
    "    if error_contexts:\n",
    "        print(\"\\nExample error context:\")\n",
    "        print(f\"Timestamp: {error_contexts[0]['timestamp']}\")\n",
    "        print(f\"Error: {error_contexts[0]['error_log']}\")\n",
    "        print(\"Context logs:\")\n",
    "        for i, log in enumerate(error_contexts[0]['context_logs']):\n",
    "            print(f\"  {i+1}. {log[:100]}{'...' if len(log) > 100 else ''}\")\n",
    "else:\n",
    "    print(\"No logs available for extracting error contexts.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710ddffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_error_with_llm(error_context, agent_executor):\n",
    "    \"\"\"Analyze a single error context using the LLM agent.\n",
    "    \n",
    "    Args:\n",
    "        error_context: Dictionary containing error context\n",
    "        agent_executor: LangChain agent executor to use for analysis\n",
    "        \n",
    "    Returns:\n",
    "        Analysis result from the agent\n",
    "    \"\"\"\n",
    "    # Format the error and context as a prompt\n",
    "    error_prompt = f\"\"\"Analyze this error and provide a solution:\n",
    "    \n",
    "    Error log: {error_context['error_log']}\n",
    "    \n",
    "    Context (surrounding log entries):\n",
    "    \"\"\"\n",
    "    \n",
    "    # Add the context logs\n",
    "    for i, log in enumerate(error_context['context_logs']):\n",
    "        error_prompt += f\"\\n{i+1}. {log}\"\n",
    "    \n",
    "    # Add any additional labels/metadata\n",
    "    if error_context['labels']:\n",
    "        error_prompt += \"\\n\\nAdditional context:\"\n",
    "        for key, value in error_context['labels'].items():\n",
    "            error_prompt += f\"\\n{key}: {value}\"\n",
    "    \n",
    "    # Run analysis with the agent\n",
    "    try:\n",
    "        result = agent_executor.invoke({\"input\": error_prompt})\n",
    "        return {\n",
    "            'timestamp': error_context['timestamp'],\n",
    "            'error_log': error_context['error_log'],\n",
    "            'analysis': result['output']\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'timestamp': error_context['timestamp'],\n",
    "            'error_log': error_context['error_log'],\n",
    "            'analysis': f\"Error during analysis: {str(e)}\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c42b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze a sample of errors using our LLM agent\n",
    "if 'error_contexts' in locals() and error_contexts:\n",
    "    # Take a sample of up to 3 errors to analyze (to limit API usage)\n",
    "    sample_size = min(3, len(error_contexts))\n",
    "    sample_errors = error_contexts[:sample_size]\n",
    "    \n",
    "    analyses = []\n",
    "    for i, error_context in enumerate(sample_errors):\n",
    "        print(f\"Analyzing error {i+1}/{sample_size}...\")\n",
    "        analysis = analyze_error_with_llm(error_context, agent_executor)\n",
    "        analyses.append(analysis)\n",
    "    \n",
    "    # Display the analyses\n",
    "    for i, analysis in enumerate(analyses):\n",
    "        print(f\"\\n--- Error Analysis {i+1} ---\")\n",
    "        print(f\"Timestamp: {analysis['timestamp']}\")\n",
    "        print(f\"Error: {analysis['error_log']}\")\n",
    "        print(f\"\\nAnalysis & Solution:\\n{analysis['analysis']}\")\n",
    "        print(\"\\n\" + \"-\"*50)\n",
    "else:\n",
    "    print(\"No error contexts available to analyze.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
